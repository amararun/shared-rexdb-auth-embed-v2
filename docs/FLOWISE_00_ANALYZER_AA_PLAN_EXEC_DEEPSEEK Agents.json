{
  "nodes": [
    {
      "id": "chatOpenAI_0",
      "position": {
        "x": -1518.96641838166,
        "y": 523.7057049257645
      },
      "type": "customNode",
      "data": {
        "id": "chatOpenAI_0",
        "label": "ChatOpenAI",
        "version": 8.1,
        "name": "chatOpenAI",
        "type": "ChatOpenAI",
        "baseClasses": [
          "ChatOpenAI",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "openAIApi"
            ],
            "id": "chatOpenAI_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "gpt-4o-mini",
            "id": "chatOpenAI_0-input-modelName-asyncOptions"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatOpenAI_0-input-temperature-number"
          },
          {
            "label": "Streaming",
            "name": "streaming",
            "type": "boolean",
            "default": true,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-streaming-boolean"
          },
          {
            "label": "Max Tokens",
            "name": "maxTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-maxTokens-number"
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-topP-number"
          },
          {
            "label": "Frequency Penalty",
            "name": "frequencyPenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-frequencyPenalty-number"
          },
          {
            "label": "Presence Penalty",
            "name": "presencePenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-presencePenalty-number"
          },
          {
            "label": "Timeout",
            "name": "timeout",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-timeout-number"
          },
          {
            "label": "Strict Tool Calling",
            "name": "strictToolCalling",
            "type": "boolean",
            "description": "Whether the model supports the `strict` argument when passing in tools. If not specified, the `strict` argument will not be passed to OpenAI.",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-strictToolCalling-boolean"
          },
          {
            "label": "Stop Sequence",
            "name": "stopSequence",
            "type": "string",
            "rows": 4,
            "optional": true,
            "description": "List of stop words to use when generating. Use comma to separate multiple stop words.",
            "additionalParams": true,
            "id": "chatOpenAI_0-input-stopSequence-string"
          },
          {
            "label": "BasePath",
            "name": "basepath",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-basepath-string"
          },
          {
            "label": "Proxy Url",
            "name": "proxyUrl",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-proxyUrl-string"
          },
          {
            "label": "BaseOptions",
            "name": "baseOptions",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-baseOptions-json"
          },
          {
            "label": "Allow Image Uploads",
            "name": "allowImageUploads",
            "type": "boolean",
            "description": "Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" target=\"_blank\">docs</a> for more details.",
            "default": false,
            "optional": true,
            "id": "chatOpenAI_0-input-allowImageUploads-boolean"
          },
          {
            "label": "Image Resolution",
            "description": "This parameter controls the resolution in which the model views the image.",
            "name": "imageResolution",
            "type": "options",
            "options": [
              {
                "label": "Low",
                "name": "low"
              },
              {
                "label": "High",
                "name": "high"
              },
              {
                "label": "Auto",
                "name": "auto"
              }
            ],
            "default": "low",
            "optional": false,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-imageResolution-options"
          },
          {
            "label": "Reasoning Effort",
            "description": "Constrains effort on reasoning for reasoning models. Only applicable for o1 models",
            "name": "reasoningEffort",
            "type": "options",
            "options": [
              {
                "label": "Low",
                "name": "low"
              },
              {
                "label": "Medium",
                "name": "medium"
              },
              {
                "label": "High",
                "name": "high"
              }
            ],
            "default": "low",
            "optional": false,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-reasoningEffort-options"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatOpenAI_0-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "gpt-4o-mini",
          "temperature": "0.0",
          "streaming": true,
          "maxTokens": "",
          "topP": "",
          "frequencyPenalty": "",
          "presencePenalty": "",
          "timeout": "",
          "strictToolCalling": "",
          "stopSequence": "",
          "basepath": "",
          "proxyUrl": "",
          "baseOptions": "",
          "allowImageUploads": "",
          "imageResolution": "low",
          "reasoningEffort": "low"
        },
        "outputAnchors": [
          {
            "id": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatOpenAI",
            "label": "ChatOpenAI",
            "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
            "type": "ChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 669,
      "selected": false,
      "positionAbsolute": {
        "x": -1518.96641838166,
        "y": 523.7057049257645
      },
      "dragging": false
    },
    {
      "id": "sqliteAgentMemory_0",
      "position": {
        "x": -1523.5853581950228,
        "y": 1530.4005762332602
      },
      "type": "customNode",
      "data": {
        "id": "sqliteAgentMemory_0",
        "label": "SQLite Agent Memory",
        "version": 1,
        "name": "sqliteAgentMemory",
        "type": "SQLiteAgentMemory",
        "baseClasses": [
          "SQLiteAgentMemory",
          "BaseCheckpointSaver"
        ],
        "category": "Memory",
        "description": "Memory for agentflow to remember the state of the conversation using SQLite database",
        "inputParams": [
          {
            "label": "Additional Connection Configuration",
            "name": "additionalConfig",
            "type": "json",
            "additionalParams": true,
            "optional": true,
            "id": "sqliteAgentMemory_0-input-additionalConfig-json"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "additionalConfig": ""
        },
        "outputAnchors": [
          {
            "id": "sqliteAgentMemory_0-output-sqliteAgentMemory-SQLiteAgentMemory|BaseCheckpointSaver",
            "name": "sqliteAgentMemory",
            "label": "SQLiteAgentMemory",
            "description": "Memory for agentflow to remember the state of the conversation using SQLite database",
            "type": "SQLiteAgentMemory | BaseCheckpointSaver"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 251,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": -1523.5853581950228,
        "y": 1530.4005762332602
      }
    },
    {
      "id": "seqStart_0",
      "position": {
        "x": -1524.3561320242507,
        "y": 94.63222701503014
      },
      "type": "customNode",
      "data": {
        "id": "seqStart_0",
        "label": "Start",
        "version": 2,
        "name": "seqStart",
        "type": "Start",
        "baseClasses": [
          "Start"
        ],
        "category": "Sequential Agents",
        "description": "Starting point of the conversation",
        "inputParams": [],
        "inputAnchors": [
          {
            "label": "Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat",
            "id": "seqStart_0-input-model-BaseChatModel"
          },
          {
            "label": "Agent Memory",
            "name": "agentMemory",
            "type": "BaseCheckpointSaver",
            "description": "Save the state of the agent",
            "optional": true,
            "id": "seqStart_0-input-agentMemory-BaseCheckpointSaver"
          },
          {
            "label": "State",
            "name": "state",
            "type": "State",
            "description": "State is an object that is updated by nodes in the graph, passing from one node to another. By default, state contains \"messages\" that got updated with each message sent and received.",
            "optional": true,
            "id": "seqStart_0-input-state-State"
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "seqStart_0-input-inputModeration-Moderation"
          }
        ],
        "inputs": {
          "model": "{{chatOpenAI_0.data.instance}}",
          "agentMemory": "{{sqliteAgentMemory_0.data.instance}}",
          "state": "{{seqState_0.data.instance}}",
          "inputModeration": ""
        },
        "outputAnchors": [
          {
            "id": "seqStart_0-output-seqStart-Start",
            "name": "seqStart",
            "label": "Start",
            "description": "Starting point of the conversation",
            "type": "Start"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 382,
      "selected": false,
      "positionAbsolute": {
        "x": -1524.3561320242507,
        "y": 94.63222701503014
      },
      "dragging": false
    },
    {
      "id": "seqState_0",
      "position": {
        "x": -1549.4650440630246,
        "y": 1238.8773271482828
      },
      "type": "customNode",
      "data": {
        "id": "seqState_0",
        "label": "State",
        "version": 2,
        "name": "seqState",
        "type": "State",
        "baseClasses": [
          "State"
        ],
        "category": "Sequential Agents",
        "description": "A centralized state object, updated by nodes in the graph, passing from one node to another",
        "inputParams": [
          {
            "label": "Custom State",
            "name": "stateMemory",
            "type": "tabs",
            "tabIdentifier": "selectedStateTab",
            "additionalParams": true,
            "default": "stateMemoryUI",
            "tabs": [
              {
                "label": "Custom State (Table)",
                "name": "stateMemoryUI",
                "type": "datagrid",
                "description": "Structure for state. By default, state contains \"messages\" that got updated with each message sent and received.",
                "hint": {
                  "label": "How to use",
                  "value": "\nSpecify the Key, Operation Type, and Default Value for the state object. The Operation Type can be either \"Replace\" or \"Append\".\n\n**Replace**\n- Replace the existing value with the new value.\n- If the new value is null, the existing value will be retained.\n\n**Append**\n- Append the new value to the existing value.\n- Default value can be empty or an array. Ex: [\"a\", \"b\"]\n- Final value is an array.\n"
                },
                "datagrid": [
                  {
                    "field": "key",
                    "headerName": "Key",
                    "editable": true
                  },
                  {
                    "field": "type",
                    "headerName": "Operation",
                    "type": "singleSelect",
                    "valueOptions": [
                      "Replace",
                      "Append"
                    ],
                    "editable": true
                  },
                  {
                    "field": "defaultValue",
                    "headerName": "Default Value",
                    "flex": 1,
                    "editable": true
                  }
                ],
                "optional": true,
                "additionalParams": true
              },
              {
                "label": "Custom State (Code)",
                "name": "stateMemoryCode",
                "type": "code",
                "description": "JSON object representing the state",
                "hideCodeExecute": true,
                "codeExample": "{\n    aggregate: {\n        value: (x, y) => x.concat(y), // here we append the new message to the existing messages\n        default: () => []\n    }\n}",
                "optional": true,
                "additionalParams": true
              }
            ],
            "id": "seqState_0-input-stateMemory-tabs"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "stateMemory": "stateMemoryUI",
          "stateMemoryUI": "[{\"key\":\"database_schema\",\"type\":\"Replace\",\"defaultValue\":\"Sample Rows \\\"category\\\",\\\"date\\\",\\\"bank_name\\\",\\\"atm_crm_onsite_nos\\\",\\\"atm_crm_offsite_nos\\\",\\\"pos_nos\\\",\\\"micro_atm_nos\\\",\\\"bharat_qr_codes_nos\\\",\\\"upi_qr_codes_nos\\\",\\\"credit_cards_nos\\\",\\\"debit_cards_nos\\\",\\\"credit_card_pos_txn_volume_nos\\\",\\\"credit_card_pos_txn_value_amt\\\",\\\"credit_card_ecom_volume_nos\\\",\\\"credit_card_ecom_value_amt\\\",\\\"credit_card_others_volume_nos\\\",\\\"credit_card_others_value_amt\\\",\\\"cash_withdrawal_atm_volume_nos\\\",\\\"cash_withdrawal_atm_value_amt\\\",\\\"debit_card_pos_txn_volume_nos\\\",\\\"debit_card_pos_txn_value_amt\\\",\\\"debit_card_ecom_volume_nos\\\",\\\"debit_card_ecom_value_amt\\\",\\\"debit_card_others_volume_nos\\\",\\\"debit_card_others_value_amt\\\",\\\"cash_withdrawal_atm_volume_nos_1\\\",\\\"cash_withdrawal_atm_value_amt_1\\\",\\\"cash_withdrawal_pos_volume_nos\\\",\\\"cash_withdrawal_pos_value_amt\\\" Public Sector Banks,2024-04-30,BANK OF BARODA,8083,2631,38491,45378,11605,1872633,2553872,95799680,2467681,9313995.465960002,2265594,14227260.683199998,0,0.0,19695,96520.53646,4124584,9652288.358290002,501908,2699354.2322500004,23,71.303,25103105,125165873.536,387,424.832 Public Sector Banks,2024-04-30,BANK OF INDIA,5329,2900,43215,18933,0,1102836,75738,45111110,150000,589651.42516,62534,292553.82398000004,0,0.0,8833,54594.986520000006,2758192,5992010.72468,804363,1316958.3661,0,0.0,15945755,67443078.859,929,965.726 Public Sector Banks,2024-04-30,BANK OF MAHARASHTRA,1970,85,1466,1844,355014,966623,32900,13667691,51240,227083.54421000005,18754,105286.75877,0,0.0,901,4488.6,1296840,2310869.14942,314593,562317.44538,5623,64595.78285,5859767,26355974.234830003,0,0.0 Public Sector Banks,2024-04-30,CANARA BANK,8217,3953,75919,13167,0,2299219,864054,57567033,997065,3704214.36187,398404,2131549.73143,0,0.0,88198,485351.0,6590098,18014556.38504,1126096,3806986.64141,4004,63959.745,32623190,158401732.702,540,473.59 Public Sector Banks,2024-04-30,CENTRAL BANK OF INDIA,2857,1144,3060,2453,18935,1302722,0,29024244,0,0.0,0,0.0,0,0.0,0,0.0,1683951,4178629.173,269538,810234.117,0,0.0,9086255,43634101.396,4137,4388.001 Public Sector Banks,2024-04-30,INDIAN BANK,4383,606,21590,11322,0,2648048,222890,32289290,203158,876020.52999,117208,961579.18383,0,0.0,4836,35367.254,3458204,8363665.14001,848457,1770045.4576300003,3556,59671.42137,20256553,96728776.89409,7630,7592.7 Public Sector Banks,2024-04-30,INDIAN OVERSEAS BANK,2773,732,0,0,0,371117,82752,18336099,69692,202277.35636,19359,67913.45788,0,0.0,2458,12191.50945,2497672,5761605.00037,501075,1060055.99772,0,0.0,11979763,51395639.60775,0,0.0    Here are the counts of records by month from the table public.RBICC_COMBINED_FULL2024_76215: Month\\tCount 2024-01-01\\t65 2024-02-01\\t65 2024-03-01\\t65 2024-04-01\\t64 2024-05-01\\t64 2024-06-01\\t64 2024-07-01\\t64 2024-08-01\\t64 2024-09-01\\t64 2024-10-01\\t64 2024-11-01\\t64 2024-12-01\\t64\",\"actions\":\"\",\"id\":1}]",
          "selectedStateTab_seqState_0": "stateMemoryUI",
          "stateMemoryCode": "{\n    aggregate: {\n        value: (x, y) => x.concat(y), // here we append the new message to the existing messages\n        default: () => []\n    }\n}"
        },
        "outputAnchors": [
          {
            "id": "seqState_0-output-seqState-State",
            "name": "seqState",
            "label": "State",
            "description": "A centralized state object, updated by nodes in the graph, passing from one node to another",
            "type": "State"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 251,
      "selected": false,
      "positionAbsolute": {
        "x": -1549.4650440630246,
        "y": 1238.8773271482828
      },
      "dragging": false
    },
    {
      "id": "seqAgent_1",
      "position": {
        "x": 299.0129805249727,
        "y": -479.8924799463107
      },
      "type": "customNode",
      "data": {
        "id": "seqAgent_1",
        "label": "Agent",
        "version": 4.1,
        "name": "seqAgent",
        "type": "Agent",
        "baseClasses": [
          "Agent"
        ],
        "category": "Sequential Agents",
        "description": "Agent that can execute tools",
        "inputParams": [
          {
            "label": "Agent Name",
            "name": "agentName",
            "type": "string",
            "placeholder": "Agent",
            "id": "seqAgent_1-input-agentName-string"
          },
          {
            "label": "System Prompt",
            "name": "systemMessagePrompt",
            "type": "string",
            "rows": 4,
            "optional": true,
            "default": "You are a research assistant who can search for up-to-date info using search engine.",
            "id": "seqAgent_1-input-systemMessagePrompt-string"
          },
          {
            "label": "Prepend Messages History",
            "name": "messageHistory",
            "description": "Prepend a list of messages between System Prompt and Human Prompt. This is useful when you want to provide few shot examples",
            "type": "code",
            "hideCodeExecute": true,
            "codeExample": "const { AIMessage, HumanMessage, ToolMessage } = require('@langchain/core/messages');\n\nreturn [\n    new HumanMessage(\"What is 333382 ðŸ¦œ 1932?\"),\n    new AIMessage({\n        content: \"\",\n        tool_calls: [\n        {\n            id: \"12345\",\n            name: \"calulator\",\n            args: {\n                number1: 333382,\n                number2: 1932,\n                operation: \"divide\",\n            },\n        },\n        ],\n    }),\n    new ToolMessage({\n        tool_call_id: \"12345\",\n        content: \"The answer is 172.558.\",\n    }),\n    new AIMessage(\"The answer is 172.558.\"),\n]",
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_1-input-messageHistory-code"
          },
          {
            "label": "Conversation History",
            "name": "conversationHistorySelection",
            "type": "options",
            "options": [
              {
                "label": "User Question",
                "name": "user_question",
                "description": "Use the user question from the historical conversation messages as input."
              },
              {
                "label": "Last Conversation Message",
                "name": "last_message",
                "description": "Use the last conversation message from the historical conversation messages as input."
              },
              {
                "label": "All Conversation Messages",
                "name": "all_messages",
                "description": "Use all conversation messages from the historical conversation messages as input."
              },
              {
                "label": "Empty",
                "name": "empty",
                "description": "Do not use any messages from the conversation history. Ensure to use either System Prompt, Human Prompt, or Messages History."
              }
            ],
            "default": "all_messages",
            "optional": true,
            "description": "Select which messages from the conversation history to include in the prompt. The selected messages will be inserted between the System Prompt (if defined) and [Messages History, Human Prompt].",
            "additionalParams": true,
            "id": "seqAgent_1-input-conversationHistorySelection-options"
          },
          {
            "label": "Human Prompt",
            "name": "humanMessagePrompt",
            "type": "string",
            "description": "This prompt will be added at the end of the messages as human message",
            "rows": 4,
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_1-input-humanMessagePrompt-string"
          },
          {
            "label": "Require Approval",
            "name": "interrupt",
            "description": "Pause execution and request user approval before running tools.\nIf enabled, the agent will prompt the user with customizable approve/reject options\nand will proceed only after approval. This requires a configured agent memory to manage\nthe state and handle approval requests.\nIf no tools are invoked, the agent proceeds without interruption.",
            "type": "boolean",
            "optional": true,
            "id": "seqAgent_1-input-interrupt-boolean"
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "description": "Assign values to the prompt variables. You can also use $flow.state.<variable-name> to get the state value",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "seqAgent_1-input-promptValues-json"
          },
          {
            "label": "Approval Prompt",
            "name": "approvalPrompt",
            "description": "Prompt for approval. Only applicable if \"Require Approval\" is enabled",
            "type": "string",
            "default": "You are about to execute tool: {tools}. Ask if user want to proceed",
            "rows": 4,
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_1-input-approvalPrompt-string"
          },
          {
            "label": "Approve Button Text",
            "name": "approveButtonText",
            "description": "Text for approve button. Only applicable if \"Require Approval\" is enabled",
            "type": "string",
            "default": "Yes",
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_1-input-approveButtonText-string"
          },
          {
            "label": "Reject Button Text",
            "name": "rejectButtonText",
            "description": "Text for reject button. Only applicable if \"Require Approval\" is enabled",
            "type": "string",
            "default": "No",
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_1-input-rejectButtonText-string"
          },
          {
            "label": "Update State",
            "name": "updateStateMemory",
            "type": "tabs",
            "tabIdentifier": "selectedUpdateStateMemoryTab",
            "additionalParams": true,
            "default": "updateStateMemoryUI",
            "tabs": [
              {
                "label": "Update State (Table)",
                "name": "updateStateMemoryUI",
                "type": "datagrid",
                "hint": {
                  "label": "How to use",
                  "value": "\n1. Key and value pair to be updated. For example: if you have the following State:\n    | Key       | Operation     | Default Value     |\n    |-----------|---------------|-------------------|\n    | user      | Replace       |                   |\n\n    You can update the \"user\" value with the following:\n    | Key       | Value     |\n    |-----------|-----------|\n    | user      | john doe  |\n\n2. If you want to use the Agent's output as the value to update state, it is available as available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": \"Hello! How can I assist you today?\",\n        \"usedTools\": [\n            {\n                \"tool\": \"tool-name\",\n                \"toolInput\": \"{foo: var}\",\n                \"toolOutput\": \"This is the tool's output\"\n            }\n        ],\n        \"sourceDocuments\": [\n            {\n                \"pageContent\": \"This is the page content\",\n                \"metadata\": \"{foo: var}\"\n            }\n        ]\n    }\n    ```\n\n    For example, if the `toolOutput` is the value you want to update the state with, you can do the following:\n    | Key       | Value                                     |\n    |-----------|-------------------------------------------|\n    | user      | `$flow.output.usedTools[0].toolOutput`  |\n\n3. You can get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"
                },
                "description": "This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values",
                "datagrid": [
                  {
                    "field": "key",
                    "headerName": "Key",
                    "type": "asyncSingleSelect",
                    "loadMethod": "loadStateKeys",
                    "flex": 0.5,
                    "editable": true
                  },
                  {
                    "field": "value",
                    "headerName": "Value",
                    "type": "freeSolo",
                    "valueOptions": [
                      {
                        "label": "Agent Output (string)",
                        "value": "$flow.output.content"
                      },
                      {
                        "label": "Used Tools (array)",
                        "value": "$flow.output.usedTools"
                      },
                      {
                        "label": "First Tool Output (string)",
                        "value": "$flow.output.usedTools[0].toolOutput"
                      },
                      {
                        "label": "Source Documents (array)",
                        "value": "$flow.output.sourceDocuments"
                      },
                      {
                        "label": "Global variable (string)",
                        "value": "$vars.<variable-name>"
                      },
                      {
                        "label": "Input Question (string)",
                        "value": "$flow.input"
                      },
                      {
                        "label": "Session Id (string)",
                        "value": "$flow.sessionId"
                      },
                      {
                        "label": "Chat Id (string)",
                        "value": "$flow.chatId"
                      },
                      {
                        "label": "Chatflow Id (string)",
                        "value": "$flow.chatflowId"
                      }
                    ],
                    "editable": true,
                    "flex": 1
                  }
                ],
                "optional": true,
                "additionalParams": true
              },
              {
                "label": "Update State (Code)",
                "name": "updateStateMemoryCode",
                "type": "code",
                "hint": {
                  "label": "How to use",
                  "value": "\n1. Return the key value JSON object. For example: if you have the following State:\n    ```json\n    {\n        \"user\": null\n    }\n    ```\n\n    You can update the \"user\" value by returning the following:\n    ```js\n    return {\n        \"user\": \"john doe\"\n    }\n    ```\n\n2. If you want to use the agent's output as the value to update state, it is available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": \"Hello! How can I assist you today?\",\n        \"usedTools\": [\n            {\n                \"tool\": \"tool-name\",\n                \"toolInput\": \"{foo: var}\",\n                \"toolOutput\": \"This is the tool's output\"\n            }\n        ],\n        \"sourceDocuments\": [\n            {\n                \"pageContent\": \"This is the page content\",\n                \"metadata\": \"{foo: var}\"\n            }\n        ]\n    }\n    ```\n\n    For example, if the `toolOutput` is the value you want to update the state with, you can return the following:\n    ```js\n    return {\n        \"user\": $flow.output.usedTools[0].toolOutput\n    }\n    ```\n\n3. You can also get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"
                },
                "description": "This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values. Must return an object representing the state",
                "hideCodeExecute": true,
                "codeExample": "const result = $flow.output;\n\n/* Suppose we have a custom State schema like this:\n* {\n    aggregate: {\n        value: (x, y) => x.concat(y),\n        default: () => []\n    }\n  }\n*/\n\nreturn {\n  aggregate: [result.content]\n};",
                "optional": true,
                "additionalParams": true
              }
            ],
            "id": "seqAgent_1-input-updateStateMemory-tabs"
          },
          {
            "label": "Max Iterations",
            "name": "maxIterations",
            "type": "number",
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_1-input-maxIterations-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "optional": true,
            "id": "seqAgent_1-input-tools-Tool"
          },
          {
            "label": "Sequential Node",
            "name": "sequentialNode",
            "type": "Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow",
            "description": "Can be connected to one of the following nodes: Start, Agent, Condition, LLM Node, Tool Node, Custom Function, Execute Flow",
            "list": true,
            "id": "seqAgent_1-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"
          },
          {
            "label": "Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "optional": true,
            "description": "Overwrite model to be used for this agent",
            "id": "seqAgent_1-input-model-BaseChatModel"
          }
        ],
        "inputs": {
          "agentName": "agent_executor",
          "systemMessagePrompt": "REVIEWER plus Execution\n\nYour primary task is to review analysis plan provided by the advanced analyst, execute it, analyze result of the queries and share insights and analysis report in format specified below\n\nResponsibilities:\n\n1. Review SQL Query  \n   - Ensure accuracy and compliance with the specified database type (MySQL, PostgreSQL, etc.).  \n   - Verify alignment with provided credentials and schema.  \n   - Identify and correct errors before executionâ€”fix issues related to:  \n       - Syntax errors, missing table references, incorrect joins, and data type mismatches.  \n       - Logical errors, ensuring calculations and aggregations are correct.  \n       - Common pitfalls such as division by zero (use COALESCE(), NULLIF(), or appropriate handling).  \n       - Multi-statement execution issuesâ€”separate queries if needed for compatibility.  \n       - Foreign key constraints and missing dependenciesâ€”ensure queries run in the correct order.  \n       - Make sure there is a LIMIT clause in any SELECT query. By default, use LIMIT 100 unless a smaller number is explicitly required for ranking or other purposes.\n\n       - Above was not an exhaustive list - could be anything else also - evaluate critically\n   - If errors persist after execution, debug iteratively, refining until successful.  \n\n2. Execute Query  \n   - Run the SQL query using the database tool.  \n\n3. Visualizations & Statistical Analysis  \n   - For visualizations, go as per guidance from the advance analyst.\n   - Generate and execute Python code for computations and visualizations.  \n\n4. Share Analysis Report. Analyze the actual results and share the following\n   - Well-formatted markdown with headings, subheadings, tables, and necessary formatting.  \n   - At least three visualizations.  \n   - Structured sections - suggested format below. Modify based on analysis/ user request.  \n     a. Header - specific, incisive and attention grabbing header based on the analysis (max 100 characters)\n     b. Analysis Objective â€“ goal.  \n     c. Methodology - DETAILED methodology, formulas used, calculations and assumptions \n     d. Results / Insights â€“ key findings with actual numbers after executing queries. Share tables (format) as appropriate. \n     g. Recommendations â€“ 2-5 actionable business suggestions - based on actual numbers\n  - This is the final report. Makes sure TO share actual numbers as part of your results and insights.\n  - Make sure to report is supported by numbers, KPIs, tables and detailed methodology and assumptions.\n \n\n",
          "messageHistory": "",
          "conversationHistorySelection": "all_messages",
          "humanMessagePrompt": "",
          "tools": [
            "{{customTool_0.data.instance}}",
            "{{codeInterpreterE2B_0.data.instance}}"
          ],
          "sequentialNode": [
            "{{seqLLMNode_0.data.instance}}",
            "{{seqConditionAgent_0.data.instance}}",
            "{{seqLLMNode_0.data.instance}}"
          ],
          "model": "{{chatOpenAI_4.data.instance}}",
          "interrupt": "",
          "promptValues": "",
          "approvalPrompt": "You are about to execute tool: {tools}. Ask if user want to proceed",
          "approveButtonText": "Yes",
          "rejectButtonText": "No",
          "updateStateMemory": "updateStateMemoryUI",
          "maxIterations": ""
        },
        "outputAnchors": [
          {
            "id": "seqAgent_1-output-seqAgent-Agent",
            "name": "seqAgent",
            "label": "Agent",
            "description": "Agent that can execute tools",
            "type": "Agent"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 858,
      "selected": false,
      "positionAbsolute": {
        "x": 299.0129805249727,
        "y": -479.8924799463107
      },
      "dragging": false
    },
    {
      "id": "customTool_0",
      "position": {
        "x": -77.23994186516722,
        "y": 817.058792580043
      },
      "type": "customNode",
      "data": {
        "id": "customTool_0",
        "label": "Custom Tool",
        "version": 3,
        "name": "customTool",
        "type": "CustomTool",
        "baseClasses": [
          "CustomTool",
          "Tool",
          "StructuredTool",
          "Runnable"
        ],
        "category": "Tools",
        "description": "Use custom tool you've created in Flowise within chatflow",
        "inputParams": [
          {
            "label": "Select Tool",
            "name": "selectedTool",
            "type": "asyncOptions",
            "loadMethod": "listTools",
            "id": "customTool_0-input-selectedTool-asyncOptions"
          },
          {
            "label": "Return Direct",
            "name": "returnDirect",
            "description": "Return the output of the tool directly to the user",
            "type": "boolean",
            "optional": true,
            "id": "customTool_0-input-returnDirect-boolean"
          },
          {
            "label": "Custom Tool Name",
            "name": "customToolName",
            "type": "string",
            "hidden": true,
            "id": "customTool_0-input-customToolName-string"
          },
          {
            "label": "Custom Tool Description",
            "name": "customToolDesc",
            "type": "string",
            "hidden": true,
            "id": "customTool_0-input-customToolDesc-string"
          },
          {
            "label": "Custom Tool Schema",
            "name": "customToolSchema",
            "type": "string",
            "hidden": true,
            "id": "customTool_0-input-customToolSchema-string"
          },
          {
            "label": "Custom Tool Func",
            "name": "customToolFunc",
            "type": "string",
            "hidden": true,
            "id": "customTool_0-input-customToolFunc-string"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "selectedTool": "0462b728-ac16-4db5-9516-2ef0cefdd92a",
          "returnDirect": "",
          "customToolName": "",
          "customToolDesc": "",
          "customToolSchema": "",
          "customToolFunc": ""
        },
        "outputAnchors": [
          {
            "id": "customTool_0-output-customTool-CustomTool|Tool|StructuredTool|Runnable",
            "name": "customTool",
            "label": "CustomTool",
            "description": "Use custom tool you've created in Flowise within chatflow",
            "type": "CustomTool | Tool | StructuredTool | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 371,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": -77.23994186516722,
        "y": 817.058792580043
      }
    },
    {
      "id": "codeInterpreterE2B_0",
      "position": {
        "x": 311.6694695512169,
        "y": 427.5149415343999
      },
      "type": "customNode",
      "data": {
        "id": "codeInterpreterE2B_0",
        "label": "Code Interpreter by E2B",
        "version": 1,
        "name": "codeInterpreterE2B",
        "type": "CodeInterpreter",
        "baseClasses": [
          "CodeInterpreter",
          "Tool",
          "StructuredTool",
          "Runnable"
        ],
        "category": "Tools",
        "description": "Execute code in a sandbox environment",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "E2BApi"
            ],
            "optional": true,
            "id": "codeInterpreterE2B_0-input-credential-credential"
          },
          {
            "label": "Tool Name",
            "name": "toolName",
            "type": "string",
            "description": "Specify the name of the tool",
            "default": "code_interpreter",
            "id": "codeInterpreterE2B_0-input-toolName-string"
          },
          {
            "label": "Tool Description",
            "name": "toolDesc",
            "type": "string",
            "rows": 4,
            "description": "Specify the description of the tool",
            "default": "Evaluates python code in a sandbox environment. The environment is long running and exists across multiple executions. You must send the whole script every time and print your outputs. Script should be pure python code that can be evaluated. It should be in python format NOT markdown. The code should NOT be wrapped in backticks. All python packages including requests, matplotlib, scipy, numpy, pandas, etc are available. Create and display chart using \"plt.show()\".",
            "id": "codeInterpreterE2B_0-input-toolDesc-string"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "toolName": "code_interpreter",
          "toolDesc": "Use this to prepare python charts and statistical analysis. Evaluates python code in a sandbox environment. The environment is long running and exists across multiple executions. You must send the whole script every time and print your outputs. Script should be pure python code that can be evaluated. It should be in python format NOT markdown. The code should NOT be wrapped in backticks. All python packages including requests, matplotlib, scipy, numpy, pandas, etc are available. Create and display chart using \"plt.show()\"."
        },
        "outputAnchors": [
          {
            "id": "codeInterpreterE2B_0-output-codeInterpreterE2B-CodeInterpreter|Tool|StructuredTool|Runnable",
            "name": "codeInterpreterE2B",
            "label": "CodeInterpreter",
            "description": "Execute code in a sandbox environment",
            "type": "CodeInterpreter | Tool | StructuredTool | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 550,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 311.6694695512169,
        "y": 427.5149415343999
      }
    },
    {
      "id": "seqConditionAgent_0",
      "position": {
        "x": -1107.9103396007986,
        "y": 340.05604739862235
      },
      "type": "customNode",
      "data": {
        "id": "seqConditionAgent_0",
        "label": "Condition Agent",
        "version": 3.1,
        "name": "seqConditionAgent",
        "type": "ConditionAgent",
        "baseClasses": [
          "ConditionAgent"
        ],
        "category": "Sequential Agents",
        "description": "Uses an agent to determine which route to take next",
        "inputParams": [
          {
            "label": "Name",
            "name": "conditionAgentName",
            "type": "string",
            "placeholder": "Condition Agent",
            "id": "seqConditionAgent_0-input-conditionAgentName-string"
          },
          {
            "label": "System Prompt",
            "name": "systemMessagePrompt",
            "type": "string",
            "rows": 4,
            "default": "You are an expert customer support routing system.\nYour job is to detect whether a customer support representative is routing a user to the technical support team, or just responding conversationally.",
            "additionalParams": true,
            "optional": true,
            "id": "seqConditionAgent_0-input-systemMessagePrompt-string"
          },
          {
            "label": "Conversation History",
            "name": "conversationHistorySelection",
            "type": "options",
            "options": [
              {
                "label": "User Question",
                "name": "user_question",
                "description": "Use the user question from the historical conversation messages as input."
              },
              {
                "label": "Last Conversation Message",
                "name": "last_message",
                "description": "Use the last conversation message from the historical conversation messages as input."
              },
              {
                "label": "All Conversation Messages",
                "name": "all_messages",
                "description": "Use all conversation messages from the historical conversation messages as input."
              },
              {
                "label": "Empty",
                "name": "empty",
                "description": "Do not use any messages from the conversation history. Ensure to use either System Prompt, Human Prompt, or Messages History."
              }
            ],
            "default": "all_messages",
            "optional": true,
            "description": "Select which messages from the conversation history to include in the prompt. The selected messages will be inserted between the System Prompt (if defined) and Human Prompt.",
            "additionalParams": true,
            "id": "seqConditionAgent_0-input-conversationHistorySelection-options"
          },
          {
            "label": "Human Prompt",
            "name": "humanMessagePrompt",
            "type": "string",
            "description": "This prompt will be added at the end of the messages as human message",
            "rows": 4,
            "default": "The previous conversation is an interaction between a customer support representative and a user.\nExtract whether the representative is routing the user to the technical support team, or just responding conversationally.\n\nIf representative want to route the user to the technical support team, respond only with the word \"TECHNICAL\".\nOtherwise, respond only with the word \"CONVERSATION\".\n\nRemember, only respond with one of the above words.",
            "additionalParams": true,
            "optional": true,
            "id": "seqConditionAgent_0-input-humanMessagePrompt-string"
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "description": "Assign values to the prompt variables. You can also use $flow.state.<variable-name> to get the state value",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "additionalParams": true,
            "id": "seqConditionAgent_0-input-promptValues-json"
          },
          {
            "label": "JSON Structured Output",
            "name": "conditionAgentStructuredOutput",
            "type": "datagrid",
            "description": "Instruct the LLM to give output in a JSON structured schema",
            "datagrid": [
              {
                "field": "key",
                "headerName": "Key",
                "editable": true
              },
              {
                "field": "type",
                "headerName": "Type",
                "type": "singleSelect",
                "valueOptions": [
                  "String",
                  "String Array",
                  "Number",
                  "Boolean",
                  "Enum"
                ],
                "editable": true
              },
              {
                "field": "enumValues",
                "headerName": "Enum Values",
                "editable": true
              },
              {
                "field": "description",
                "headerName": "Description",
                "flex": 1,
                "editable": true
              }
            ],
            "optional": true,
            "additionalParams": true,
            "id": "seqConditionAgent_0-input-conditionAgentStructuredOutput-datagrid"
          },
          {
            "label": "Condition",
            "name": "condition",
            "type": "conditionFunction",
            "tabIdentifier": "selectedConditionFunctionTab",
            "tabs": [
              {
                "label": "Condition (Table)",
                "name": "conditionUI",
                "type": "datagrid",
                "description": "If a condition is met, the node connected to the respective output will be executed",
                "optional": true,
                "datagrid": [
                  {
                    "field": "variable",
                    "headerName": "Variable",
                    "type": "freeSolo",
                    "editable": true,
                    "loadMethod": [
                      "getPreviousMessages",
                      "loadStateKeys"
                    ],
                    "valueOptions": [
                      {
                        "label": "Agent Output (string)",
                        "value": "$flow.output.content"
                      },
                      {
                        "label": "Agent's JSON Key Output (string)",
                        "value": "$flow.output.<replace-with-key>"
                      },
                      {
                        "label": "Total Messages (number)",
                        "value": "$flow.state.messages.length"
                      },
                      {
                        "label": "First Message Content (string)",
                        "value": "$flow.state.messages[0].content"
                      },
                      {
                        "label": "Last Message Content (string)",
                        "value": "$flow.state.messages[-1].content"
                      },
                      {
                        "label": "Global variable (string)",
                        "value": "$vars.<variable-name>"
                      }
                    ],
                    "flex": 0.5,
                    "minWidth": 200
                  },
                  {
                    "field": "operation",
                    "headerName": "Operation",
                    "type": "singleSelect",
                    "valueOptions": [
                      "Contains",
                      "Not Contains",
                      "Start With",
                      "End With",
                      "Is",
                      "Is Not",
                      "Is Empty",
                      "Is Not Empty",
                      "Greater Than",
                      "Less Than",
                      "Equal To",
                      "Not Equal To",
                      "Greater Than or Equal To",
                      "Less Than or Equal To"
                    ],
                    "editable": true,
                    "flex": 0.4,
                    "minWidth": 150
                  },
                  {
                    "field": "value",
                    "headerName": "Value",
                    "flex": 1,
                    "editable": true
                  },
                  {
                    "field": "output",
                    "headerName": "Output Name",
                    "editable": true,
                    "flex": 0.3,
                    "minWidth": 150
                  }
                ]
              },
              {
                "label": "Condition (Code)",
                "name": "conditionFunction",
                "type": "code",
                "description": "Function to evaluate the condition",
                "hint": {
                  "label": "How to use",
                  "value": "\n1. Must return a string value at the end of function. For example:\n    ```js\n    if (\"X\" === \"X\") {\n        return \"Agent\"; // connect to next agent node\n    } else {\n        return \"End\"; // connect to end node\n    }\n    ```\n\n2. In most cases, you would probably get the last message to do some comparison. You can get all current messages from the state: `$flow.state.messages`:\n    ```json\n    [\n        {\n            \"content\": \"Hello! How can I assist you today?\",\n            \"name\": \"\",\n            \"additional_kwargs\": {},\n            \"response_metadata\": {},\n            \"tool_calls\": [],\n            \"invalid_tool_calls\": [],\n            \"usage_metadata\": {}\n        }\n    ]\n    ```\n\n    For example, to get the last message content:\n    ```js\n    const messages = $flow.state.messages;\n    const lastMessage = messages[messages.length - 1];\n\n    // Proceed to do something with the last message content\n    ```\n\n3. If you want to use the Condition Agent's output for conditional checks, it is available as `$flow.output` with the following structure:\n\n    ```json\n    {\n        \"content\": 'Hello! How can I assist you today?',\n        \"name\": \"\",\n        \"additional_kwargs\": {},\n        \"response_metadata\": {},\n        \"tool_calls\": [],\n        \"invalid_tool_calls\": [],\n        \"usage_metadata\": {}\n    }\n    ```\n\n    For example, we can check if the agent's output contains specific keyword:\n    ```js\n    const result = $flow.output.content;\n    \n    if (result.includes(\"some-keyword\")) {\n        return \"Agent\"; // connect to next agent node\n    } else {\n        return \"End\"; // connect to end node\n    }\n    ```\n\n    If Structured Output is enabled, `$flow.output` will be in the JSON format as defined in the Structured Output configuration:\n    ```json\n    {\n        \"foo\": 'var'\n    }\n    ```\n\n4. You can get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n5. You can get custom variables: `$vars.<variable-name>`\n\n"
                },
                "hideCodeExecute": true,
                "codeExample": "const result = $flow.output.content;\n\nif (result.includes(\"some-keyword\")) {\n    return \"Agent\";\n}\n\nreturn \"End\";\n",
                "optional": true
              }
            ],
            "id": "seqConditionAgent_0-input-condition-conditionFunction"
          }
        ],
        "inputAnchors": [
          {
            "label": "Sequential Node",
            "name": "sequentialNode",
            "type": "Start | Agent | LLMNode | ToolNode | CustomFunction | ExecuteFlow",
            "description": "Can be connected to one of the following nodes: Start, Agent, LLM Node, Tool Node, Custom Function, Execute Flow",
            "list": true,
            "id": "seqConditionAgent_0-input-sequentialNode-Start | Agent | LLMNode | ToolNode | CustomFunction | ExecuteFlow"
          },
          {
            "label": "Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "optional": true,
            "description": "Overwrite model to be used for this agent",
            "id": "seqConditionAgent_0-input-model-BaseChatModel"
          }
        ],
        "inputs": {
          "conditionAgentName": "router_agent",
          "sequentialNode": [
            "{{seqStart_0.data.instance}}"
          ],
          "model": "",
          "systemMessagePrompt": "In the previous conversation, you will find an interaction between the user and the agent. Your task is to analyze the conversation and determine the appropriate agent to handle the request. You have two routing options:\n\n## Simple Analyst Agent\nThis should be the default choice unless the request requires step-by-step / advanced reasoning or the user specifically asks for Advanced Analyst \n\n- Optimized for faster execution and direct SQL query handling without advanced reasoning.\n- Can handle both simple and complex SQL queries, generate results efficiently, and process most database-related requests.\n- Use this agent for all general SQL queries, including:\n  - CRUD operations (Create, Read, Update, Delete)\n  - SELECT queries and charts (unless advanced reasoning is needed)\n  - Ranking-based queries (e.g., top-ranked items by a variable)\n  - Connection testing requests\n-  Complex SQL queries also which dont need step-by-step reasoning\n- Do NOT escalate to Advanced Analyst unless really necessary.\n- If the request requires a Simple Analyst Agent, respond with 'SIMPLE'.\n\n## Advanced Analyst Agent\n- Powered by gpt-O3 mini, with advanced reasoning capabilities.\n- Can execute SQL queries, generate Python charts, and analyze database relationships.\n- Only use this agent when:\n  - The user explicitly requests \"advanced analysis\" or \"detailed insights.\"\n - The query requires step-by-step reasoning or insightful interpretations (e.g., variable relationships, finding insightful ratios).\n- Do NOT use for general SQL queries or CRUD operations.\n- If the request requires an Advanced Analyst Agent, respond with 'ADVANCED'.\n\n### Routing Rules:\n- Default to Simple Analyst.\n- Route to Advanced Analyst ONLY when reasoning-based analysis is required.\n- SQL complexity alone does NOT determine the routing decision. Even complex queries should go to Simple Analyst unless step-by-step reasoning is necessary.\n",
          "conversationHistorySelection": "all_messages",
          "humanMessagePrompt": "In the previous conversation, you will find an interaction between the user and the agent. Your task is to analyze the conversation and determine the appropriate agent to handle the request . Share your decision as specified in the system prompt",
          "promptValues": "",
          "conditionAgentStructuredOutput": "[{\"key\":\"route\",\"type\":\"Enum\",\"enumValues\":\"SIMPLE, ADVANCED\",\"description\":\"routing decision - SIMPLE for simpler questions and ADVANCED for more advanced and reasoning based questions\",\"actions\":\"\",\"id\":1}]",
          "condition": "",
          "conditionUI": "[{\"variable\":\"$flow.output.route\",\"operation\":\"Is\",\"value\":\"SIMPLE\",\"output\":\"SIMPLE\",\"actions\":\"\",\"id\":1},{\"variable\":\"$flow.output.route\",\"operation\":\"Is\",\"value\":\"ADVANCED\",\"output\":\"ADVANCED\",\"actions\":\"\",\"id\":2}]",
          "selectedConditionFunctionTab_seqConditionAgent_0": "conditionUI"
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "options": [
              {
                "id": "seqConditionAgent_0-output-advanced-Condition",
                "name": "advanced",
                "label": "ADVANCED",
                "type": "Condition",
                "isAnchor": true
              },
              {
                "id": "seqConditionAgent_0-output-end-Condition",
                "name": "end",
                "label": "End",
                "type": "Condition",
                "isAnchor": true
              },
              {
                "id": "seqConditionAgent_0-output-simple-Condition",
                "name": "simple",
                "label": "SIMPLE",
                "type": "Condition",
                "isAnchor": true
              }
            ]
          }
        ],
        "outputs": {
          "output": "next"
        },
        "selected": false
      },
      "width": 300,
      "height": 627,
      "positionAbsolute": {
        "x": -1107.9103396007986,
        "y": 340.05604739862235
      },
      "selected": false,
      "dragging": false
    },
    {
      "id": "seqAgent_2",
      "position": {
        "x": -81.92196691918653,
        "y": 1829.8630633014695
      },
      "type": "customNode",
      "data": {
        "id": "seqAgent_2",
        "label": "Agent",
        "version": 4.1,
        "name": "seqAgent",
        "type": "Agent",
        "baseClasses": [
          "Agent"
        ],
        "category": "Sequential Agents",
        "description": "Agent that can execute tools",
        "inputParams": [
          {
            "label": "Agent Name",
            "name": "agentName",
            "type": "string",
            "placeholder": "Agent",
            "id": "seqAgent_2-input-agentName-string"
          },
          {
            "label": "System Prompt",
            "name": "systemMessagePrompt",
            "type": "string",
            "rows": 4,
            "optional": true,
            "default": "You are a research assistant who can search for up-to-date info using search engine.",
            "id": "seqAgent_2-input-systemMessagePrompt-string"
          },
          {
            "label": "Prepend Messages History",
            "name": "messageHistory",
            "description": "Prepend a list of messages between System Prompt and Human Prompt. This is useful when you want to provide few shot examples",
            "type": "code",
            "hideCodeExecute": true,
            "codeExample": "const { AIMessage, HumanMessage, ToolMessage } = require('@langchain/core/messages');\n\nreturn [\n    new HumanMessage(\"What is 333382 ðŸ¦œ 1932?\"),\n    new AIMessage({\n        content: \"\",\n        tool_calls: [\n        {\n            id: \"12345\",\n            name: \"calulator\",\n            args: {\n                number1: 333382,\n                number2: 1932,\n                operation: \"divide\",\n            },\n        },\n        ],\n    }),\n    new ToolMessage({\n        tool_call_id: \"12345\",\n        content: \"The answer is 172.558.\",\n    }),\n    new AIMessage(\"The answer is 172.558.\"),\n]",
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_2-input-messageHistory-code"
          },
          {
            "label": "Conversation History",
            "name": "conversationHistorySelection",
            "type": "options",
            "options": [
              {
                "label": "User Question",
                "name": "user_question",
                "description": "Use the user question from the historical conversation messages as input."
              },
              {
                "label": "Last Conversation Message",
                "name": "last_message",
                "description": "Use the last conversation message from the historical conversation messages as input."
              },
              {
                "label": "All Conversation Messages",
                "name": "all_messages",
                "description": "Use all conversation messages from the historical conversation messages as input."
              },
              {
                "label": "Empty",
                "name": "empty",
                "description": "Do not use any messages from the conversation history. Ensure to use either System Prompt, Human Prompt, or Messages History."
              }
            ],
            "default": "all_messages",
            "optional": true,
            "description": "Select which messages from the conversation history to include in the prompt. The selected messages will be inserted between the System Prompt (if defined) and [Messages History, Human Prompt].",
            "additionalParams": true,
            "id": "seqAgent_2-input-conversationHistorySelection-options"
          },
          {
            "label": "Human Prompt",
            "name": "humanMessagePrompt",
            "type": "string",
            "description": "This prompt will be added at the end of the messages as human message",
            "rows": 4,
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_2-input-humanMessagePrompt-string"
          },
          {
            "label": "Require Approval",
            "name": "interrupt",
            "description": "Pause execution and request user approval before running tools.\nIf enabled, the agent will prompt the user with customizable approve/reject options\nand will proceed only after approval. This requires a configured agent memory to manage\nthe state and handle approval requests.\nIf no tools are invoked, the agent proceeds without interruption.",
            "type": "boolean",
            "optional": true,
            "id": "seqAgent_2-input-interrupt-boolean"
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "description": "Assign values to the prompt variables. You can also use $flow.state.<variable-name> to get the state value",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "seqAgent_2-input-promptValues-json"
          },
          {
            "label": "Approval Prompt",
            "name": "approvalPrompt",
            "description": "Prompt for approval. Only applicable if \"Require Approval\" is enabled",
            "type": "string",
            "default": "You are about to execute tool: {tools}. Ask if user want to proceed",
            "rows": 4,
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_2-input-approvalPrompt-string"
          },
          {
            "label": "Approve Button Text",
            "name": "approveButtonText",
            "description": "Text for approve button. Only applicable if \"Require Approval\" is enabled",
            "type": "string",
            "default": "Yes",
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_2-input-approveButtonText-string"
          },
          {
            "label": "Reject Button Text",
            "name": "rejectButtonText",
            "description": "Text for reject button. Only applicable if \"Require Approval\" is enabled",
            "type": "string",
            "default": "No",
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_2-input-rejectButtonText-string"
          },
          {
            "label": "Update State",
            "name": "updateStateMemory",
            "type": "tabs",
            "tabIdentifier": "selectedUpdateStateMemoryTab",
            "additionalParams": true,
            "default": "updateStateMemoryUI",
            "tabs": [
              {
                "label": "Update State (Table)",
                "name": "updateStateMemoryUI",
                "type": "datagrid",
                "hint": {
                  "label": "How to use",
                  "value": "\n1. Key and value pair to be updated. For example: if you have the following State:\n    | Key       | Operation     | Default Value     |\n    |-----------|---------------|-------------------|\n    | user      | Replace       |                   |\n\n    You can update the \"user\" value with the following:\n    | Key       | Value     |\n    |-----------|-----------|\n    | user      | john doe  |\n\n2. If you want to use the Agent's output as the value to update state, it is available as available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": \"Hello! How can I assist you today?\",\n        \"usedTools\": [\n            {\n                \"tool\": \"tool-name\",\n                \"toolInput\": \"{foo: var}\",\n                \"toolOutput\": \"This is the tool's output\"\n            }\n        ],\n        \"sourceDocuments\": [\n            {\n                \"pageContent\": \"This is the page content\",\n                \"metadata\": \"{foo: var}\"\n            }\n        ]\n    }\n    ```\n\n    For example, if the `toolOutput` is the value you want to update the state with, you can do the following:\n    | Key       | Value                                     |\n    |-----------|-------------------------------------------|\n    | user      | `$flow.output.usedTools[0].toolOutput`  |\n\n3. You can get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"
                },
                "description": "This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values",
                "datagrid": [
                  {
                    "field": "key",
                    "headerName": "Key",
                    "type": "asyncSingleSelect",
                    "loadMethod": "loadStateKeys",
                    "flex": 0.5,
                    "editable": true
                  },
                  {
                    "field": "value",
                    "headerName": "Value",
                    "type": "freeSolo",
                    "valueOptions": [
                      {
                        "label": "Agent Output (string)",
                        "value": "$flow.output.content"
                      },
                      {
                        "label": "Used Tools (array)",
                        "value": "$flow.output.usedTools"
                      },
                      {
                        "label": "First Tool Output (string)",
                        "value": "$flow.output.usedTools[0].toolOutput"
                      },
                      {
                        "label": "Source Documents (array)",
                        "value": "$flow.output.sourceDocuments"
                      },
                      {
                        "label": "Global variable (string)",
                        "value": "$vars.<variable-name>"
                      },
                      {
                        "label": "Input Question (string)",
                        "value": "$flow.input"
                      },
                      {
                        "label": "Session Id (string)",
                        "value": "$flow.sessionId"
                      },
                      {
                        "label": "Chat Id (string)",
                        "value": "$flow.chatId"
                      },
                      {
                        "label": "Chatflow Id (string)",
                        "value": "$flow.chatflowId"
                      }
                    ],
                    "editable": true,
                    "flex": 1
                  }
                ],
                "optional": true,
                "additionalParams": true
              },
              {
                "label": "Update State (Code)",
                "name": "updateStateMemoryCode",
                "type": "code",
                "hint": {
                  "label": "How to use",
                  "value": "\n1. Return the key value JSON object. For example: if you have the following State:\n    ```json\n    {\n        \"user\": null\n    }\n    ```\n\n    You can update the \"user\" value by returning the following:\n    ```js\n    return {\n        \"user\": \"john doe\"\n    }\n    ```\n\n2. If you want to use the agent's output as the value to update state, it is available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": \"Hello! How can I assist you today?\",\n        \"usedTools\": [\n            {\n                \"tool\": \"tool-name\",\n                \"toolInput\": \"{foo: var}\",\n                \"toolOutput\": \"This is the tool's output\"\n            }\n        ],\n        \"sourceDocuments\": [\n            {\n                \"pageContent\": \"This is the page content\",\n                \"metadata\": \"{foo: var}\"\n            }\n        ]\n    }\n    ```\n\n    For example, if the `toolOutput` is the value you want to update the state with, you can return the following:\n    ```js\n    return {\n        \"user\": $flow.output.usedTools[0].toolOutput\n    }\n    ```\n\n3. You can also get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"
                },
                "description": "This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values. Must return an object representing the state",
                "hideCodeExecute": true,
                "codeExample": "const result = $flow.output;\n\n/* Suppose we have a custom State schema like this:\n* {\n    aggregate: {\n        value: (x, y) => x.concat(y),\n        default: () => []\n    }\n  }\n*/\n\nreturn {\n  aggregate: [result.content]\n};",
                "optional": true,
                "additionalParams": true
              }
            ],
            "id": "seqAgent_2-input-updateStateMemory-tabs"
          },
          {
            "label": "Max Iterations",
            "name": "maxIterations",
            "type": "number",
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_2-input-maxIterations-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "optional": true,
            "id": "seqAgent_2-input-tools-Tool"
          },
          {
            "label": "Sequential Node",
            "name": "sequentialNode",
            "type": "Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow",
            "description": "Can be connected to one of the following nodes: Start, Agent, Condition, LLM Node, Tool Node, Custom Function, Execute Flow",
            "list": true,
            "id": "seqAgent_2-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"
          },
          {
            "label": "Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "optional": true,
            "description": "Overwrite model to be used for this agent",
            "id": "seqAgent_2-input-model-BaseChatModel"
          }
        ],
        "inputs": {
          "agentName": "agent_simple_analyst",
          "systemMessagePrompt": "EXECUTOR / GENERAL ANALYST\n\n- Primary Task:  \n  - Prepare, execute, and validate SQL queries to answer the user's request accurately.  \n  - Ensure compliance with the database type (MySQL, PostgreSQL, SQLite, etc.).  \n  - Share the executed SQL query along with results for transparency.  \n\n1. Create the SQL Query:  \n   - Construct an SQL query that correctly addresses the userâ€™s request.  \n   - Ensure accuracy and compliance with the provided database credentials and schema.  \n   - Identify and correct errors before execution. This includes:  \n     - Syntax errors, incorrect joins, missing tables, and data type mismatches.  \n     - Logical errors in aggregations, conditions, or calculations.  \n     - Common pitfalls like division by zero (use COALESCE(), NULLIF(), or appropriate handling).  \n     - Ensuring queries run in the correct order when multiple queries are needed.  \n       - Make sure there is a LIMIT clause in any SELECT query. By default, use LIMIT 100 unless a smaller number is explicitly required for ranking or other purposes.\n   - If a request requires multiple queries for efficiency, break them into separate statements.  \n\n2. Execute the Query:  \n   - Use the appropriate database tool to execute the SQL query.  \n   - Handle any execution errors, refine the query as needed, and ensure optimal performance.  \n   - Share the final executed SQL query along with the results.  \n\n3. Handle Charts & Statistical Analysis:  \n   - If the user requests a chart or statistical analysis, generate Python code for computation and visualization.  \n   - Execute Python-based visualizations using Matplotlib, Seaborn, or appropriate tools.  \n\n4. General Chit-Chat:  \n   - If the user engages in casual conversation, gently redirect them to the primary task while maintaining a friendly and professional tone.  \n\n",
          "messageHistory": "",
          "conversationHistorySelection": "all_messages",
          "humanMessagePrompt": "",
          "tools": [
            "{{customTool_1.data.instance}}",
            "{{codeInterpreterE2B_1.data.instance}}"
          ],
          "sequentialNode": [
            "{{seqConditionAgent_0.data.instance}}"
          ],
          "model": "{{chatOpenAI_2.data.instance}}",
          "interrupt": "",
          "promptValues": "",
          "approvalPrompt": "You are about to execute tool: {tools}. Ask if user want to proceed",
          "approveButtonText": "Yes",
          "rejectButtonText": "No",
          "updateStateMemory": "updateStateMemoryUI",
          "maxIterations": ""
        },
        "outputAnchors": [
          {
            "id": "seqAgent_2-output-seqAgent-Agent",
            "name": "seqAgent",
            "label": "Agent",
            "description": "Agent that can execute tools",
            "type": "Agent"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 858,
      "selected": false,
      "positionAbsolute": {
        "x": -81.92196691918653,
        "y": 1829.8630633014695
      },
      "dragging": false
    },
    {
      "id": "customTool_1",
      "position": {
        "x": -29.601489475395283,
        "y": 2762.888570272471
      },
      "type": "customNode",
      "data": {
        "id": "customTool_1",
        "label": "Custom Tool",
        "version": 3,
        "name": "customTool",
        "type": "CustomTool",
        "baseClasses": [
          "CustomTool",
          "Tool",
          "StructuredTool",
          "Runnable"
        ],
        "category": "Tools",
        "description": "Use custom tool you've created in Flowise within chatflow",
        "inputParams": [
          {
            "label": "Select Tool",
            "name": "selectedTool",
            "type": "asyncOptions",
            "loadMethod": "listTools",
            "id": "customTool_1-input-selectedTool-asyncOptions"
          },
          {
            "label": "Return Direct",
            "name": "returnDirect",
            "description": "Return the output of the tool directly to the user",
            "type": "boolean",
            "optional": true,
            "id": "customTool_1-input-returnDirect-boolean"
          },
          {
            "label": "Custom Tool Name",
            "name": "customToolName",
            "type": "string",
            "hidden": true,
            "id": "customTool_1-input-customToolName-string"
          },
          {
            "label": "Custom Tool Description",
            "name": "customToolDesc",
            "type": "string",
            "hidden": true,
            "id": "customTool_1-input-customToolDesc-string"
          },
          {
            "label": "Custom Tool Schema",
            "name": "customToolSchema",
            "type": "string",
            "hidden": true,
            "id": "customTool_1-input-customToolSchema-string"
          },
          {
            "label": "Custom Tool Func",
            "name": "customToolFunc",
            "type": "string",
            "hidden": true,
            "id": "customTool_1-input-customToolFunc-string"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "selectedTool": "0462b728-ac16-4db5-9516-2ef0cefdd92a",
          "returnDirect": "",
          "customToolName": "",
          "customToolDesc": "",
          "customToolSchema": "",
          "customToolFunc": ""
        },
        "outputAnchors": [
          {
            "id": "customTool_1-output-customTool-CustomTool|Tool|StructuredTool|Runnable",
            "name": "customTool",
            "label": "CustomTool",
            "description": "Use custom tool you've created in Flowise within chatflow",
            "type": "CustomTool | Tool | StructuredTool | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 371,
      "selected": false,
      "positionAbsolute": {
        "x": -29.601489475395283,
        "y": 2762.888570272471
      },
      "dragging": false
    },
    {
      "id": "codeInterpreterE2B_1",
      "position": {
        "x": -366.31502197766883,
        "y": 2785.062455954705
      },
      "type": "customNode",
      "data": {
        "id": "codeInterpreterE2B_1",
        "label": "Code Interpreter by E2B",
        "version": 1,
        "name": "codeInterpreterE2B",
        "type": "CodeInterpreter",
        "baseClasses": [
          "CodeInterpreter",
          "Tool",
          "StructuredTool",
          "Runnable"
        ],
        "category": "Tools",
        "description": "Execute code in a sandbox environment",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "E2BApi"
            ],
            "optional": true,
            "id": "codeInterpreterE2B_1-input-credential-credential"
          },
          {
            "label": "Tool Name",
            "name": "toolName",
            "type": "string",
            "description": "Specify the name of the tool",
            "default": "code_interpreter",
            "id": "codeInterpreterE2B_1-input-toolName-string"
          },
          {
            "label": "Tool Description",
            "name": "toolDesc",
            "type": "string",
            "rows": 4,
            "description": "Specify the description of the tool",
            "default": "Evaluates python code in a sandbox environment. The environment is long running and exists across multiple executions. You must send the whole script every time and print your outputs. Script should be pure python code that can be evaluated. It should be in python format NOT markdown. The code should NOT be wrapped in backticks. All python packages including requests, matplotlib, scipy, numpy, pandas, etc are available. Create and display chart using \"plt.show()\".",
            "id": "codeInterpreterE2B_1-input-toolDesc-string"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "toolName": "code_interpreter",
          "toolDesc": "Use this to prepare python charts and statistical analysis. Evaluates python code in a sandbox environment. The environment is long running and exists across multiple executions. You must send the whole script every time and print your outputs. Script should be pure python code that can be evaluated. It should be in python format NOT markdown. The code should NOT be wrapped in backticks. All python packages including requests, matplotlib, scipy, numpy, pandas, etc are available. Create and display chart using \"plt.show()\"."
        },
        "outputAnchors": [
          {
            "id": "codeInterpreterE2B_1-output-codeInterpreterE2B-CodeInterpreter|Tool|StructuredTool|Runnable",
            "name": "codeInterpreterE2B",
            "label": "CodeInterpreter",
            "description": "Execute code in a sandbox environment",
            "type": "CodeInterpreter | Tool | StructuredTool | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 550,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": -366.31502197766883,
        "y": 2785.062455954705
      }
    },
    {
      "id": "seqEnd_1",
      "position": {
        "x": -818.454149184715,
        "y": 1212.9424147496359
      },
      "type": "customNode",
      "data": {
        "id": "seqEnd_1",
        "label": "End",
        "version": 2.1,
        "name": "seqEnd",
        "type": "End",
        "baseClasses": [
          "End"
        ],
        "category": "Sequential Agents",
        "description": "End conversation",
        "inputParams": [],
        "inputAnchors": [
          {
            "label": "Sequential Node",
            "name": "sequentialNode",
            "type": "Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow",
            "description": "Can be connected to one of the following nodes: Agent, Condition, LLM Node, Tool Node, Custom Function, Execute Flow",
            "id": "seqEnd_1-input-sequentialNode-Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"
          }
        ],
        "inputs": {
          "sequentialNode": "{{seqConditionAgent_0.data.instance}}"
        },
        "outputAnchors": [],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 143,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": -818.454149184715,
        "y": 1212.9424147496359
      }
    },
    {
      "id": "seqEnd_2",
      "position": {
        "x": 927.4697292071962,
        "y": 2316.379441412351
      },
      "type": "customNode",
      "data": {
        "id": "seqEnd_2",
        "label": "End",
        "version": 2.1,
        "name": "seqEnd",
        "type": "End",
        "baseClasses": [
          "End"
        ],
        "category": "Sequential Agents",
        "description": "End conversation",
        "inputParams": [],
        "inputAnchors": [
          {
            "label": "Sequential Node",
            "name": "sequentialNode",
            "type": "Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow",
            "description": "Can be connected to one of the following nodes: Agent, Condition, LLM Node, Tool Node, Custom Function, Execute Flow",
            "id": "seqEnd_2-input-sequentialNode-Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"
          }
        ],
        "inputs": {
          "sequentialNode": "{{seqAgent_2.data.instance}}"
        },
        "outputAnchors": [],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 143,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 927.4697292071962,
        "y": 2316.379441412351
      }
    },
    {
      "id": "chatOpenAI_2",
      "position": {
        "x": -404.37724401283936,
        "y": 2056.0398150227634
      },
      "type": "customNode",
      "data": {
        "id": "chatOpenAI_2",
        "label": "ChatOpenAI",
        "version": 8.1,
        "name": "chatOpenAI",
        "type": "ChatOpenAI",
        "baseClasses": [
          "ChatOpenAI",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "openAIApi"
            ],
            "id": "chatOpenAI_2-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "gpt-4o-mini",
            "id": "chatOpenAI_2-input-modelName-asyncOptions"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatOpenAI_2-input-temperature-number"
          },
          {
            "label": "Streaming",
            "name": "streaming",
            "type": "boolean",
            "default": true,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_2-input-streaming-boolean"
          },
          {
            "label": "Max Tokens",
            "name": "maxTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_2-input-maxTokens-number"
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_2-input-topP-number"
          },
          {
            "label": "Frequency Penalty",
            "name": "frequencyPenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_2-input-frequencyPenalty-number"
          },
          {
            "label": "Presence Penalty",
            "name": "presencePenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_2-input-presencePenalty-number"
          },
          {
            "label": "Timeout",
            "name": "timeout",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_2-input-timeout-number"
          },
          {
            "label": "Strict Tool Calling",
            "name": "strictToolCalling",
            "type": "boolean",
            "description": "Whether the model supports the `strict` argument when passing in tools. If not specified, the `strict` argument will not be passed to OpenAI.",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_2-input-strictToolCalling-boolean"
          },
          {
            "label": "Stop Sequence",
            "name": "stopSequence",
            "type": "string",
            "rows": 4,
            "optional": true,
            "description": "List of stop words to use when generating. Use comma to separate multiple stop words.",
            "additionalParams": true,
            "id": "chatOpenAI_2-input-stopSequence-string"
          },
          {
            "label": "BasePath",
            "name": "basepath",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_2-input-basepath-string"
          },
          {
            "label": "Proxy Url",
            "name": "proxyUrl",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_2-input-proxyUrl-string"
          },
          {
            "label": "BaseOptions",
            "name": "baseOptions",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_2-input-baseOptions-json"
          },
          {
            "label": "Allow Image Uploads",
            "name": "allowImageUploads",
            "type": "boolean",
            "description": "Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" target=\"_blank\">docs</a> for more details.",
            "default": false,
            "optional": true,
            "id": "chatOpenAI_2-input-allowImageUploads-boolean"
          },
          {
            "label": "Image Resolution",
            "description": "This parameter controls the resolution in which the model views the image.",
            "name": "imageResolution",
            "type": "options",
            "options": [
              {
                "label": "Low",
                "name": "low"
              },
              {
                "label": "High",
                "name": "high"
              },
              {
                "label": "Auto",
                "name": "auto"
              }
            ],
            "default": "low",
            "optional": false,
            "additionalParams": true,
            "id": "chatOpenAI_2-input-imageResolution-options"
          },
          {
            "label": "Reasoning Effort",
            "description": "Constrains effort on reasoning for reasoning models. Only applicable for o1 models",
            "name": "reasoningEffort",
            "type": "options",
            "options": [
              {
                "label": "Low",
                "name": "low"
              },
              {
                "label": "Medium",
                "name": "medium"
              },
              {
                "label": "High",
                "name": "high"
              }
            ],
            "default": "low",
            "optional": false,
            "additionalParams": true,
            "id": "chatOpenAI_2-input-reasoningEffort-options"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatOpenAI_2-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "gpt-4o-mini",
          "temperature": "0.0",
          "streaming": true,
          "maxTokens": "",
          "topP": "",
          "frequencyPenalty": "",
          "presencePenalty": "",
          "timeout": "",
          "strictToolCalling": "",
          "stopSequence": "",
          "basepath": "",
          "proxyUrl": "",
          "baseOptions": "",
          "allowImageUploads": "",
          "imageResolution": "low",
          "reasoningEffort": "low"
        },
        "outputAnchors": [
          {
            "id": "chatOpenAI_2-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatOpenAI",
            "label": "ChatOpenAI",
            "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
            "type": "ChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 669,
      "selected": false,
      "positionAbsolute": {
        "x": -404.37724401283936,
        "y": 2056.0398150227634
      },
      "dragging": false
    },
    {
      "id": "seqLLMNode_0",
      "position": {
        "x": -419.23833302342905,
        "y": -700.9281789589747
      },
      "type": "customNode",
      "data": {
        "id": "seqLLMNode_0",
        "label": "LLM Node",
        "version": 4.1,
        "name": "seqLLMNode",
        "type": "LLMNode",
        "baseClasses": [
          "LLMNode"
        ],
        "category": "Sequential Agents",
        "description": "Run Chat Model and return the output",
        "inputParams": [
          {
            "label": "Name",
            "name": "llmNodeName",
            "type": "string",
            "placeholder": "LLM",
            "id": "seqLLMNode_0-input-llmNodeName-string"
          },
          {
            "label": "System Prompt",
            "name": "systemMessagePrompt",
            "type": "string",
            "rows": 4,
            "optional": true,
            "additionalParams": true,
            "id": "seqLLMNode_0-input-systemMessagePrompt-string"
          },
          {
            "label": "Prepend Messages History",
            "name": "messageHistory",
            "description": "Prepend a list of messages between System Prompt and Human Prompt. This is useful when you want to provide few shot examples",
            "type": "code",
            "hideCodeExecute": true,
            "codeExample": "const { AIMessage, HumanMessage, ToolMessage } = require('@langchain/core/messages');\n\nreturn [\n    new HumanMessage(\"What is 333382 ðŸ¦œ 1932?\"),\n    new AIMessage({\n        content: \"\",\n        tool_calls: [\n        {\n            id: \"12345\",\n            name: \"calulator\",\n            args: {\n                number1: 333382,\n                number2: 1932,\n                operation: \"divide\",\n            },\n        },\n        ],\n    }),\n    new ToolMessage({\n        tool_call_id: \"12345\",\n        content: \"The answer is 172.558.\",\n    }),\n    new AIMessage(\"The answer is 172.558.\"),\n]",
            "optional": true,
            "additionalParams": true,
            "id": "seqLLMNode_0-input-messageHistory-code"
          },
          {
            "label": "Conversation History",
            "name": "conversationHistorySelection",
            "type": "options",
            "options": [
              {
                "label": "User Question",
                "name": "user_question",
                "description": "Use the user question from the historical conversation messages as input."
              },
              {
                "label": "Last Conversation Message",
                "name": "last_message",
                "description": "Use the last conversation message from the historical conversation messages as input."
              },
              {
                "label": "All Conversation Messages",
                "name": "all_messages",
                "description": "Use all conversation messages from the historical conversation messages as input."
              },
              {
                "label": "Empty",
                "name": "empty",
                "description": "Do not use any messages from the conversation history. Ensure to use either System Prompt, Human Prompt, or Messages History."
              }
            ],
            "default": "all_messages",
            "optional": true,
            "description": "Select which messages from the conversation history to include in the prompt. The selected messages will be inserted between the System Prompt (if defined) and [Messages History, Human Prompt].",
            "additionalParams": true,
            "id": "seqLLMNode_0-input-conversationHistorySelection-options"
          },
          {
            "label": "Human Prompt",
            "name": "humanMessagePrompt",
            "type": "string",
            "description": "This prompt will be added at the end of the messages as human message",
            "rows": 4,
            "optional": true,
            "additionalParams": true,
            "id": "seqLLMNode_0-input-humanMessagePrompt-string"
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "description": "Assign values to the prompt variables. You can also use $flow.state.<variable-name> to get the state value",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "additionalParams": true,
            "id": "seqLLMNode_0-input-promptValues-json"
          },
          {
            "label": "JSON Structured Output",
            "name": "llmStructuredOutput",
            "type": "datagrid",
            "description": "Instruct the LLM to give output in a JSON structured schema",
            "datagrid": [
              {
                "field": "key",
                "headerName": "Key",
                "editable": true
              },
              {
                "field": "type",
                "headerName": "Type",
                "type": "singleSelect",
                "valueOptions": [
                  "String",
                  "String Array",
                  "Number",
                  "Boolean",
                  "Enum"
                ],
                "editable": true
              },
              {
                "field": "enumValues",
                "headerName": "Enum Values",
                "editable": true
              },
              {
                "field": "description",
                "headerName": "Description",
                "flex": 1,
                "editable": true
              }
            ],
            "optional": true,
            "additionalParams": true,
            "id": "seqLLMNode_0-input-llmStructuredOutput-datagrid"
          },
          {
            "label": "Update State",
            "name": "updateStateMemory",
            "type": "tabs",
            "tabIdentifier": "selectedUpdateStateMemoryTab",
            "default": "updateStateMemoryUI",
            "additionalParams": true,
            "tabs": [
              {
                "label": "Update State (Table)",
                "name": "updateStateMemoryUI",
                "type": "datagrid",
                "hint": {
                  "label": "How to use",
                  "value": "\n1. Key and value pair to be updated. For example: if you have the following State:\n    | Key       | Operation     | Default Value     |\n    |-----------|---------------|-------------------|\n    | user      | Replace       |                   |\n\n    You can update the \"user\" value with the following:\n    | Key       | Value     |\n    |-----------|-----------|\n    | user      | john doe  |\n\n2. If you want to use the LLM Node's output as the value to update state, it is available as available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": 'Hello! How can I assist you today?',\n        \"name\": \"\",\n        \"additional_kwargs\": {},\n        \"response_metadata\": {},\n        \"tool_calls\": [],\n        \"invalid_tool_calls\": [],\n        \"usage_metadata\": {}\n    }\n    ```\n\n    For example, if the output `content` is the value you want to update the state with, you can do the following:\n    | Key       | Value                     |\n    |-----------|---------------------------|\n    | user      | `$flow.output.content`  |\n\n3. You can get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"
                },
                "description": "This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values",
                "datagrid": [
                  {
                    "field": "key",
                    "headerName": "Key",
                    "type": "asyncSingleSelect",
                    "loadMethod": "loadStateKeys",
                    "flex": 0.5,
                    "editable": true
                  },
                  {
                    "field": "value",
                    "headerName": "Value",
                    "type": "freeSolo",
                    "valueOptions": [
                      {
                        "label": "LLM Node Output (string)",
                        "value": "$flow.output.content"
                      },
                      {
                        "label": "LLM JSON Output Key (string)",
                        "value": "$flow.output.<replace-with-key>"
                      },
                      {
                        "label": "Global variable (string)",
                        "value": "$vars.<variable-name>"
                      },
                      {
                        "label": "Input Question (string)",
                        "value": "$flow.input"
                      },
                      {
                        "label": "Session Id (string)",
                        "value": "$flow.sessionId"
                      },
                      {
                        "label": "Chat Id (string)",
                        "value": "$flow.chatId"
                      },
                      {
                        "label": "Chatflow Id (string)",
                        "value": "$flow.chatflowId"
                      }
                    ],
                    "editable": true,
                    "flex": 1
                  }
                ],
                "optional": true,
                "additionalParams": true
              },
              {
                "label": "Update State (Code)",
                "name": "updateStateMemoryCode",
                "type": "code",
                "hint": {
                  "label": "How to use",
                  "value": "\n1. Return the key value JSON object. For example: if you have the following State:\n    ```json\n    {\n        \"user\": null\n    }\n    ```\n\n    You can update the \"user\" value by returning the following:\n    ```js\n    return {\n        \"user\": \"john doe\"\n    }\n    ```\n\n2. If you want to use the LLM Node's output as the value to update state, it is available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": 'Hello! How can I assist you today?',\n        \"name\": \"\",\n        \"additional_kwargs\": {},\n        \"response_metadata\": {},\n        \"tool_calls\": [],\n        \"invalid_tool_calls\": [],\n        \"usage_metadata\": {}\n    }\n    ```\n\n    For example, if the output `content` is the value you want to update the state with, you can return the following:\n    ```js\n    return {\n        \"user\": $flow.output.content\n    }\n    ```\n\n3. You can also get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"
                },
                "description": "This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values. Must return an object representing the state",
                "hideCodeExecute": true,
                "codeExample": "const result = $flow.output;\n\n/* Suppose we have a custom State schema like this:\n* {\n    aggregate: {\n        value: (x, y) => x.concat(y),\n        default: () => []\n    }\n  }\n*/\n\nreturn {\n  aggregate: [result.content]\n};",
                "optional": true,
                "additionalParams": true
              }
            ],
            "id": "seqLLMNode_0-input-updateStateMemory-tabs"
          }
        ],
        "inputAnchors": [
          {
            "label": "Sequential Node",
            "name": "sequentialNode",
            "type": "Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow",
            "description": "Can be connected to one of the following nodes: Start, Agent, Condition, LLM, Tool Node, Custom Function, Execute Flow",
            "list": true,
            "id": "seqLLMNode_0-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"
          },
          {
            "label": "Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "optional": true,
            "description": "Overwrite model to be used for this node",
            "id": "seqLLMNode_0-input-model-BaseChatModel"
          }
        ],
        "inputs": {
          "llmNodeName": "agent_advanced_analyst",
          "systemMessagePrompt": "PLANNER\n\nYou are an advanced data analyst responsible for preparing a well-reasoned analysis plan.\n\nResponsibility:\n1. Analyze the question to understand the business context and analytical goal.\n2. Reason through the problem step-by-step to determine the best analytical approach.\n3. Provide MySQL-compliant SQL if the database is MySQL, and PostgreSQL-compliant SQL if the database is PostgreSQL.\n4. Share up to 3 SQL queries unless the user requests more.\n5. Feel free to use CREATE TABLE and ALTER TABLE queries if they aid the analysis. However, do not use temporary tables (e.g., avoid CREATE TEMP or CREATE TEMPORARY). ALWAYS create permanent tables, even for intermediate data storage.\n6. Be extra careful about division by zero errorsâ€”use COALESCE(), NULLIF(), or other appropriate methods based on the type of query\n7. Always include a LIMIT clause in any SELECT query. By default, use LIMIT 100 unless a smaller number is explicitly required for ranking or other purposes.\n8. Avoid multiple SQL statements in a single query; separate them into individual queries for better compatibility and execution\n\n\nOutput to be shared:\n1. Your reasoning process.\n2. SQL queries based on the specified database type.\n\nImportant:\n- Focus on solving the problem with business-oriented reasoning.\n- Ensure the user has provided a schema or sample rows.\n- Once the user shares connection details, use them consistently without asking again.\n\n",
          "messageHistory": "",
          "conversationHistorySelection": "all_messages",
          "humanMessagePrompt": "",
          "sequentialNode": [
            "{{seqConditionAgent_0.data.instance}}"
          ],
          "model": "{{chatOpenRouter_0.data.instance}}",
          "promptValues": "",
          "llmStructuredOutput": "",
          "updateStateMemory": "updateStateMemoryUI"
        },
        "outputAnchors": [
          {
            "id": "seqLLMNode_0-output-seqLLMNode-LLMNode",
            "name": "seqLLMNode",
            "label": "LLMNode",
            "description": "Run Chat Model and return the output",
            "type": "LLMNode"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 431,
      "selected": false,
      "positionAbsolute": {
        "x": -419.23833302342905,
        "y": -700.9281789589747
      },
      "dragging": false
    },
    {
      "id": "chatOpenAI_4",
      "position": {
        "x": -22.87462211920885,
        "y": -131.86252054436477
      },
      "type": "customNode",
      "data": {
        "id": "chatOpenAI_4",
        "label": "ChatOpenAI",
        "version": 8.1,
        "name": "chatOpenAI",
        "type": "ChatOpenAI",
        "baseClasses": [
          "ChatOpenAI",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "openAIApi"
            ],
            "id": "chatOpenAI_4-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "gpt-4o-mini",
            "id": "chatOpenAI_4-input-modelName-asyncOptions"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatOpenAI_4-input-temperature-number"
          },
          {
            "label": "Streaming",
            "name": "streaming",
            "type": "boolean",
            "default": true,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_4-input-streaming-boolean"
          },
          {
            "label": "Max Tokens",
            "name": "maxTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_4-input-maxTokens-number"
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_4-input-topP-number"
          },
          {
            "label": "Frequency Penalty",
            "name": "frequencyPenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_4-input-frequencyPenalty-number"
          },
          {
            "label": "Presence Penalty",
            "name": "presencePenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_4-input-presencePenalty-number"
          },
          {
            "label": "Timeout",
            "name": "timeout",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_4-input-timeout-number"
          },
          {
            "label": "Strict Tool Calling",
            "name": "strictToolCalling",
            "type": "boolean",
            "description": "Whether the model supports the `strict` argument when passing in tools. If not specified, the `strict` argument will not be passed to OpenAI.",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_4-input-strictToolCalling-boolean"
          },
          {
            "label": "Stop Sequence",
            "name": "stopSequence",
            "type": "string",
            "rows": 4,
            "optional": true,
            "description": "List of stop words to use when generating. Use comma to separate multiple stop words.",
            "additionalParams": true,
            "id": "chatOpenAI_4-input-stopSequence-string"
          },
          {
            "label": "BasePath",
            "name": "basepath",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_4-input-basepath-string"
          },
          {
            "label": "Proxy Url",
            "name": "proxyUrl",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_4-input-proxyUrl-string"
          },
          {
            "label": "BaseOptions",
            "name": "baseOptions",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_4-input-baseOptions-json"
          },
          {
            "label": "Allow Image Uploads",
            "name": "allowImageUploads",
            "type": "boolean",
            "description": "Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" target=\"_blank\">docs</a> for more details.",
            "default": false,
            "optional": true,
            "id": "chatOpenAI_4-input-allowImageUploads-boolean"
          },
          {
            "label": "Image Resolution",
            "description": "This parameter controls the resolution in which the model views the image.",
            "name": "imageResolution",
            "type": "options",
            "options": [
              {
                "label": "Low",
                "name": "low"
              },
              {
                "label": "High",
                "name": "high"
              },
              {
                "label": "Auto",
                "name": "auto"
              }
            ],
            "default": "low",
            "optional": false,
            "additionalParams": true,
            "id": "chatOpenAI_4-input-imageResolution-options"
          },
          {
            "label": "Reasoning Effort",
            "description": "Constrains effort on reasoning for reasoning models. Only applicable for o1 models",
            "name": "reasoningEffort",
            "type": "options",
            "options": [
              {
                "label": "Low",
                "name": "low"
              },
              {
                "label": "Medium",
                "name": "medium"
              },
              {
                "label": "High",
                "name": "high"
              }
            ],
            "default": "low",
            "optional": false,
            "additionalParams": true,
            "id": "chatOpenAI_4-input-reasoningEffort-options"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatOpenAI_4-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "gpt-4o",
          "temperature": "0.0",
          "streaming": true,
          "maxTokens": "",
          "topP": "",
          "frequencyPenalty": "",
          "presencePenalty": "",
          "timeout": "",
          "strictToolCalling": "",
          "stopSequence": "",
          "basepath": "",
          "proxyUrl": "",
          "baseOptions": "",
          "allowImageUploads": "",
          "imageResolution": "low",
          "reasoningEffort": "low"
        },
        "outputAnchors": [
          {
            "id": "chatOpenAI_4-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatOpenAI",
            "label": "ChatOpenAI",
            "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
            "type": "ChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 669,
      "selected": false,
      "positionAbsolute": {
        "x": -22.87462211920885,
        "y": -131.86252054436477
      },
      "dragging": false
    },
    {
      "id": "seqEnd_0",
      "position": {
        "x": 1092.0099511264038,
        "y": 126.35253101061619
      },
      "type": "customNode",
      "data": {
        "id": "seqEnd_0",
        "label": "End",
        "version": 2.1,
        "name": "seqEnd",
        "type": "End",
        "baseClasses": [
          "End"
        ],
        "category": "Sequential Agents",
        "description": "End conversation",
        "inputParams": [],
        "inputAnchors": [
          {
            "label": "Sequential Node",
            "name": "sequentialNode",
            "type": "Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow",
            "description": "Can be connected to one of the following nodes: Agent, Condition, LLM Node, Tool Node, Custom Function, Execute Flow",
            "id": "seqEnd_0-input-sequentialNode-Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"
          }
        ],
        "inputs": {
          "sequentialNode": "{{seqAgent_1.data.instance}}"
        },
        "outputAnchors": [],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 143,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 1092.0099511264038,
        "y": 126.35253101061619
      }
    },
    {
      "id": "chatOpenRouter_0",
      "position": {
        "x": -854.3546089187154,
        "y": -485.2356560976199
      },
      "type": "customNode",
      "data": {
        "id": "chatOpenRouter_0",
        "label": "ChatOpenRouter",
        "version": 1,
        "name": "chatOpenRouter",
        "type": "ChatOpenRouter",
        "baseClasses": [
          "ChatOpenRouter",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around Open Router Inference API",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "openRouterApi"
            ],
            "optional": true,
            "id": "chatOpenRouter_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "string",
            "placeholder": "openai/gpt-3.5-turbo",
            "id": "chatOpenRouter_0-input-modelName-string"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatOpenRouter_0-input-temperature-number"
          },
          {
            "label": "Streaming",
            "name": "streaming",
            "type": "boolean",
            "default": true,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenRouter_0-input-streaming-boolean"
          },
          {
            "label": "Max Tokens",
            "name": "maxTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenRouter_0-input-maxTokens-number"
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenRouter_0-input-topP-number"
          },
          {
            "label": "Frequency Penalty",
            "name": "frequencyPenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenRouter_0-input-frequencyPenalty-number"
          },
          {
            "label": "Presence Penalty",
            "name": "presencePenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenRouter_0-input-presencePenalty-number"
          },
          {
            "label": "Timeout",
            "name": "timeout",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenRouter_0-input-timeout-number"
          },
          {
            "label": "BasePath",
            "name": "basepath",
            "type": "string",
            "optional": true,
            "default": "https://openrouter.ai/api/v1",
            "additionalParams": true,
            "id": "chatOpenRouter_0-input-basepath-string"
          },
          {
            "label": "BaseOptions",
            "name": "baseOptions",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenRouter_0-input-baseOptions-json"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatOpenRouter_0-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "deepseek/deepseek-r1",
          "temperature": "0.5",
          "streaming": true,
          "maxTokens": "",
          "topP": "",
          "frequencyPenalty": "",
          "presencePenalty": "",
          "timeout": "",
          "basepath": "https://openrouter.ai/api/v1",
          "baseOptions": ""
        },
        "outputAnchors": [
          {
            "id": "chatOpenRouter_0-output-chatOpenRouter-ChatOpenRouter|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatOpenRouter",
            "label": "ChatOpenRouter",
            "description": "Wrapper around Open Router Inference API",
            "type": "ChatOpenRouter | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 575,
      "selected": false,
      "positionAbsolute": {
        "x": -854.3546089187154,
        "y": -485.2356560976199
      },
      "dragging": false
    }
  ],
  "edges": [
    {
      "source": "sqliteAgentMemory_0",
      "sourceHandle": "sqliteAgentMemory_0-output-sqliteAgentMemory-SQLiteAgentMemory|BaseCheckpointSaver",
      "target": "seqStart_0",
      "targetHandle": "seqStart_0-input-agentMemory-BaseCheckpointSaver",
      "type": "buttonedge",
      "id": "sqliteAgentMemory_0-sqliteAgentMemory_0-output-sqliteAgentMemory-SQLiteAgentMemory|BaseCheckpointSaver-seqStart_0-seqStart_0-input-agentMemory-BaseCheckpointSaver"
    },
    {
      "source": "chatOpenAI_0",
      "sourceHandle": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "seqStart_0",
      "targetHandle": "seqStart_0-input-model-BaseChatModel",
      "type": "buttonedge",
      "id": "chatOpenAI_0-chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-seqStart_0-seqStart_0-input-model-BaseChatModel"
    },
    {
      "source": "seqState_0",
      "sourceHandle": "seqState_0-output-seqState-State",
      "target": "seqStart_0",
      "targetHandle": "seqStart_0-input-state-State",
      "type": "buttonedge",
      "id": "seqState_0-seqState_0-output-seqState-State-seqStart_0-seqStart_0-input-state-State"
    },
    {
      "source": "customTool_0",
      "sourceHandle": "customTool_0-output-customTool-CustomTool|Tool|StructuredTool|Runnable",
      "target": "seqAgent_1",
      "targetHandle": "seqAgent_1-input-tools-Tool",
      "type": "buttonedge",
      "id": "customTool_0-customTool_0-output-customTool-CustomTool|Tool|StructuredTool|Runnable-seqAgent_1-seqAgent_1-input-tools-Tool"
    },
    {
      "source": "codeInterpreterE2B_0",
      "sourceHandle": "codeInterpreterE2B_0-output-codeInterpreterE2B-CodeInterpreter|Tool|StructuredTool|Runnable",
      "target": "seqAgent_1",
      "targetHandle": "seqAgent_1-input-tools-Tool",
      "type": "buttonedge",
      "id": "codeInterpreterE2B_0-codeInterpreterE2B_0-output-codeInterpreterE2B-CodeInterpreter|Tool|StructuredTool|Runnable-seqAgent_1-seqAgent_1-input-tools-Tool"
    },
    {
      "source": "seqStart_0",
      "sourceHandle": "seqStart_0-output-seqStart-Start",
      "target": "seqConditionAgent_0",
      "targetHandle": "seqConditionAgent_0-input-sequentialNode-Start | Agent | LLMNode | ToolNode | CustomFunction | ExecuteFlow",
      "type": "buttonedge",
      "id": "seqStart_0-seqStart_0-output-seqStart-Start-seqConditionAgent_0-seqConditionAgent_0-input-sequentialNode-Start | Agent | LLMNode | ToolNode | CustomFunction | ExecuteFlow"
    },
    {
      "source": "seqConditionAgent_0",
      "sourceHandle": "seqConditionAgent_0-output-simple-Condition",
      "target": "seqAgent_2",
      "targetHandle": "seqAgent_2-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow",
      "type": "buttonedge",
      "id": "seqConditionAgent_0-seqConditionAgent_0-output-simple-Condition-seqAgent_2-seqAgent_2-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"
    },
    {
      "source": "customTool_1",
      "sourceHandle": "customTool_1-output-customTool-CustomTool|Tool|StructuredTool|Runnable",
      "target": "seqAgent_2",
      "targetHandle": "seqAgent_2-input-tools-Tool",
      "type": "buttonedge",
      "id": "customTool_1-customTool_1-output-customTool-CustomTool|Tool|StructuredTool|Runnable-seqAgent_2-seqAgent_2-input-tools-Tool"
    },
    {
      "source": "codeInterpreterE2B_1",
      "sourceHandle": "codeInterpreterE2B_1-output-codeInterpreterE2B-CodeInterpreter|Tool|StructuredTool|Runnable",
      "target": "seqAgent_2",
      "targetHandle": "seqAgent_2-input-tools-Tool",
      "type": "buttonedge",
      "id": "codeInterpreterE2B_1-codeInterpreterE2B_1-output-codeInterpreterE2B-CodeInterpreter|Tool|StructuredTool|Runnable-seqAgent_2-seqAgent_2-input-tools-Tool"
    },
    {
      "source": "seqConditionAgent_0",
      "sourceHandle": "seqConditionAgent_0-output-end-Condition",
      "target": "seqEnd_1",
      "targetHandle": "seqEnd_1-input-sequentialNode-Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow",
      "type": "buttonedge",
      "id": "seqConditionAgent_0-seqConditionAgent_0-output-end-Condition-seqEnd_1-seqEnd_1-input-sequentialNode-Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"
    },
    {
      "source": "seqAgent_2",
      "sourceHandle": "seqAgent_2-output-seqAgent-Agent",
      "target": "seqEnd_2",
      "targetHandle": "seqEnd_2-input-sequentialNode-Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow",
      "type": "buttonedge",
      "id": "seqAgent_2-seqAgent_2-output-seqAgent-Agent-seqEnd_2-seqEnd_2-input-sequentialNode-Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"
    },
    {
      "source": "chatOpenAI_2",
      "sourceHandle": "chatOpenAI_2-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "seqAgent_2",
      "targetHandle": "seqAgent_2-input-model-BaseChatModel",
      "type": "buttonedge",
      "id": "chatOpenAI_2-chatOpenAI_2-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-seqAgent_2-seqAgent_2-input-model-BaseChatModel"
    },
    {
      "source": "seqConditionAgent_0",
      "sourceHandle": "seqConditionAgent_0-output-advanced-Condition",
      "target": "seqLLMNode_0",
      "targetHandle": "seqLLMNode_0-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow",
      "type": "buttonedge",
      "id": "seqConditionAgent_0-seqConditionAgent_0-output-advanced-Condition-seqLLMNode_0-seqLLMNode_0-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"
    },
    {
      "source": "seqLLMNode_0",
      "sourceHandle": "seqLLMNode_0-output-seqLLMNode-LLMNode",
      "target": "seqAgent_1",
      "targetHandle": "seqAgent_1-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow",
      "type": "buttonedge",
      "id": "seqLLMNode_0-seqLLMNode_0-output-seqLLMNode-LLMNode-seqAgent_1-seqAgent_1-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"
    },
    {
      "source": "chatOpenAI_4",
      "sourceHandle": "chatOpenAI_4-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "seqAgent_1",
      "targetHandle": "seqAgent_1-input-model-BaseChatModel",
      "type": "buttonedge",
      "id": "chatOpenAI_4-chatOpenAI_4-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-seqAgent_1-seqAgent_1-input-model-BaseChatModel"
    },
    {
      "source": "seqAgent_1",
      "sourceHandle": "seqAgent_1-output-seqAgent-Agent",
      "target": "seqEnd_0",
      "targetHandle": "seqEnd_0-input-sequentialNode-Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow",
      "type": "buttonedge",
      "id": "seqAgent_1-seqAgent_1-output-seqAgent-Agent-seqEnd_0-seqEnd_0-input-sequentialNode-Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"
    },
    {
      "source": "chatOpenRouter_0",
      "sourceHandle": "chatOpenRouter_0-output-chatOpenRouter-ChatOpenRouter|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "seqLLMNode_0",
      "targetHandle": "seqLLMNode_0-input-model-BaseChatModel",
      "type": "buttonedge",
      "id": "chatOpenRouter_0-chatOpenRouter_0-output-chatOpenRouter-ChatOpenRouter|BaseChatModel|BaseLanguageModel|Runnable-seqLLMNode_0-seqLLMNode_0-input-model-BaseChatModel"
    }
  ]
}